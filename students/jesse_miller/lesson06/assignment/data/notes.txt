'''
Notes on my changes
'''

# Something to note, this is an old 2010 MacBook Pro, dual core, no hyperthreading,
# it's going to be slower here.

# Typo in original file.

In poor_perf.py there's a typo on lines 39-40:

if new[0][6:] == '2018':
    year_count['2017'] += 1

Changing it to:

if new[0][6:] == '2018':
    year_count['2018'] += 1

# Added a print statement to get a better handle on what's happening.
'''
Unfortunately, the method I used for creating my csv is a little big to put
here, it will be attached in my pull request however as csv_generator.py
'''
eve:data jmiller$ python -m cProfile ../src/csv_generator.py exercise.csv
         405894332 function calls (405894140 primitive calls) in 745.387 seconds

# Took about 12.5 minutes.  I know I can do better, but I want to get to the
# assignment first.

'''
Running test for the first time against the million line csv that apparently
could have been a container, I found out too late...
'''

# Return values from file:

=================================== FAILURES ===================================
___________________________ test_assess_preformance ____________________________

    def test_assess_preformance():
        """ compare """
        poor = p.analyze('../data/exercise.csv')
        good = g.analyze('../data/exercise.csv')
        poor_elapsed = poor[1] - poor[0]
        good_elapsed = good[1] - good[0]
        assert good_elapsed < poor_elapsed
>       assert poor[2] == good[2]
E       AssertionError: assert {'2013': 8245...6': 8337, ...} == {'2013': 8245,...6': 8337, ...}
E         Common items:
E         {'2013': 8245, '2014': 8147, '2015': 8268, '2016': 8337}
E         Differing items:
E         {'2017': 16728} != {'2017': 8343}
E         {'2018': 0} != {'2018': 8385}
E         Full diff:
E         {'2013': 8245,
E         '2014': 8147,
E         '2015': 8268,
E         '2016': 8337,
E         -  '2017': 16728,
E         ?          ----
E         +  '2017': 8343,
E         ?           +++
E         -  '2018': 0}
E         ?          ^
E         +  '2018': 8385}
E         ?          ^^^^

test_perf.py:17: AssertionError
----------------------------- Captured stdout call -----------------------------
{'2013': 8245, '2014': 8147, '2015': 8268, '2016': 8337, '2017': 16728, '2018': 0}
'ao' was found 82515 times
{'2013': 8245, '2014': 8147, '2015': 8268, '2016': 8337, '2017': 8343, '2018': 8385}
{'2013': 8245, '2014': 8147, '2015': 8268, '2016': 8337, '2017': 8343, '2018': 8385}
'ao' was found 82515 times

# Obviously a few things to work on.

'''
Disabling the print statements so that I can see a bit clearer in the pytest output.
'''

'''
Throwing on "timeit" to get an idea of where I'm at.
'''
poor_perf.py
{'2013': 8245, '2014': 8147, '2015': 8268, '2016': 8337, '2017': 16728, '2018': 0}
'ao' was found 82515 times
164.596606512 (2.73 minutes to run)

good_perf.py (simple linting fixes)
166.157347394  (HA!)

'''
cProfile runs
'''
eve:src jmiller$ python -m cProfile -o stats good_perf.py

# Didn't really work for me.  Gave up on it.  Using LineProfiler

Timer unit: 1e-06 s

Total time: 40.1124 s
File: good_perf.py
Function: analyze at line 14

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    14                                           def analyze(filename):
    15                                               '''
    16                                               This analyzes the file for parsing via the below rules.
    17                                               '''
    18         1        233.0    233.0      0.0      start = datetime.datetime.now()
    19
    20         1        156.0    156.0      0.0      with open(filename) as csvfile:
    21         1         12.0     12.0      0.0          reader = csv.reader(csvfile, delimiter=',', quotechar='"')
    22         1          2.0      2.0      0.0          new_ones = []
    23   1000002    8105220.0      8.1     20.2          for row in reader:
    24   1000001    2296411.0      2.3      5.7              lrow = list(row)
    25   1000001    1904237.0      1.9      4.7              if lrow[5] > '00/00/2012':
    26   1000000    2162060.0      2.2      5.4                  new_ones.append((lrow[5], lrow[0]))
    27
    28                                                   year_count = {
    29         1          2.0      2.0      0.0              "2013": 0,
    30         1          2.0      2.0      0.0              "2014": 0,
    31         1          2.0      2.0      0.0              "2015": 0,
    32         1          1.0      1.0      0.0              "2016": 0,
    33         1          1.0      1.0      0.0              "2017": 0,
    34         1          2.0      2.0      0.0              "2018": 0
    35                                                   }
    36
    37   1000001    1543800.0      1.5      3.8          for new in new_ones:
    38   1000000    2036201.0      2.0      5.1              if new[0][6:] == '2013':
    39      8245      16586.0      2.0      0.0                  year_count["2013"] += 1
    40   1000000    1959348.0      2.0      4.9              if new[0][6:] == '2014':
    41      8147      16231.0      2.0      0.0                  year_count["2014"] += 1
    42   1000000    1966313.0      2.0      4.9              if new[0][6:] == '2015':
    43      8268      16645.0      2.0      0.0                  year_count["2015"] += 1
    44   1000000    1967355.0      2.0      4.9              if new[0][6:] == '2016':
    45      8337      16941.0      2.0      0.0                  year_count["2016"] += 1
    46   1000000    1973524.0      2.0      4.9              if new[0][6:] == '2017':
    47      8343      16999.0      2.0      0.0                  year_count["2017"] += 1
    48   1000000    1956525.0      2.0      4.9              if new[0][6:] == '2018':
    49      8385      17502.0      2.1      0.0                  year_count["2018"] += 1
    50
    51         1        123.0    123.0      0.0          print(year_count)
    52
    53         1        167.0    167.0      0.0      with open(filename) as csvfile:
    54         1         23.0     23.0      0.0          reader = csv.reader(csvfile, delimiter=',', quotechar='"')
    55
    56         1          2.0      2.0      0.0          found = 0
    57
    58   1000002    7645549.0      7.6     19.1          for line in reader:
    59   1000001    2331134.0      2.3      5.8              lrow = list(line)
    60   1000001    2007629.0      2.0      5.0              if "ao" in line[6]:
    61     82515     155277.0      1.9      0.4                  found += 1
    62
    63         1         52.0     52.0      0.0          print(year_count)
    64
    65         1         21.0     21.0      0.0          print(f"'ao' was found {found} times")
    66         1         60.0     60.0      0.0          end = datetime.datetime.now()
    67
    68         1          3.0      3.0      0.0      return (start, end, year_count, found)

# Well, now I know the heavy hitters.  On to fixes.

23-26 are a time sync.  Time to learn comprehensions...

'''
Attempting to fix this mess
'''

Trying:
new_ones = [row[5][-4:] for row in reader if "2012" < row[5][-4:] < "2019"]

# It saved some time:
139.65098364300002

# However, it's wrong:
{'2013': 0, '2014': 0, '2015': 0, '2016': 0, '2017': 0, '2018': 0}

# So, glass half full I suppose.  BUT!  This is because it's not actually doing
# anything.  I am an idiot.  Also, I just noticed that the functions are
# duplicated.  So we're going to fix that too.

# After a few hours of work, I came up with this:

def analyze(filename):
    '''
    This analyzes the file for parsing via the below rules.
    '''
    start = datetime.datetime.now()

    with open(filename) as csvfile:
        reader = csv.reader(csvfile, delimiter=',', quotechar='"')
        next(reader, None)  # Skipping the header row.

        new_ones = {}
        ao_total = 0


        for row in reader:
            if '2012' < row[5][-4:] < '2019':
                new_ones[row[5][-4:]] = new_ones.get(row[5][-4:], 0) + 1

            if 'ao' in row[6]:
                ao_total += 1

        end = datetime.datetime.now()

    return start, end, new_ones, ao_total

# The problem here is, it's not counting 2018 at all.  Need to sort that out.
# Of course, neither is poor perf.  Which doesn't make sense, there are 2018
# lines in there:

83655,259f4e07-6163-446b-9509-94f7c3b03cdc,583655,583655,8884057852425358,03/13/2018,awhvdijmylvapdzrdvtaykghdkexljdtpcdgsycqwriylobqrxxuejerox ezgo .


# However:
poor = 177.209565006
good = 76.97857342
# I'll call that a minor win.

# On something that isn't a 2010 MacBook Pro:
poor = 34.56443599998602
good = 17.487733999994816

# I'm imagining if I didn't have old or underpowered laptops this would be better.
# No matter how I slice it though, at least I cut the time in half.

# Correction.  good_perf is counting 2017 and 2018 correctly.  It's poor_perf 
# that is the problem.

# In other news:

eve:src jmiller$ pytest test_good_perf.py --cov=.
============================= test session starts ==============================
platform darwin -- Python 3.7.2, pytest-4.3.0, py-1.8.0, pluggy-0.8.1
rootdir: /Users/jmiller/School/Python_220/students/jesse_miller/lesson06/assignment/src, inifile:
plugins: cov-2.6.1
collected 1 item

test_good_perf.py .                                                      [100%]

---------- coverage: platform darwin, python 3.7.2-final-0 -----------
Name                Stmts   Miss  Cover
---------------------------------------
csv_generator.py       42     42     0%
good_perf.py           18      1    94%
good_scratch.py        27     27     0%
poor_perf.py           43     43     0%
test_good_perf.py       7      0   100%
test_perf.py           11     11     0%
---------------------------------------
TOTAL                 148    124    16%


=========================== 1 passed in 7.89 seconds ===========================
[master]

# Obviously I'm only testing the new file so the other stuff will fail.  94%
# coverage.

# Question though, is it supposed to loop a bunch?

'''
Next up, figure I'll try to streamline my csv generator
'''
